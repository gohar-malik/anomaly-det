{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRJD4NAvmhYyug9ZFqjnjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8f58ca16bd64a0386095fb59262f2b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0f2063af0de4816bcf17dac04f83a64",
              "IPY_MODEL_2f6c1b9a178d49b5850fb167cd003203",
              "IPY_MODEL_328c3376343d4499be380e53e0625f5c"
            ],
            "layout": "IPY_MODEL_b790bceaddfc411b828c13abc8573f3b"
          }
        },
        "e0f2063af0de4816bcf17dac04f83a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30b64780e6844aea9f8a2c2ff000c9f3",
            "placeholder": "​",
            "style": "IPY_MODEL_673d9404f3d04e5997a655152ef8b128",
            "value": "100%"
          }
        },
        "2f6c1b9a178d49b5850fb167cd003203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72135498c584ab78c80a1651cf30788",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_503478874974447da898867878b4cf76",
            "value": 170498071
          }
        },
        "328c3376343d4499be380e53e0625f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9341f630dc14230badd6f10f33d5c41",
            "placeholder": "​",
            "style": "IPY_MODEL_fd9c5ab9839c4cf983f5b0835b365e96",
            "value": " 170498071/170498071 [00:01&lt;00:00, 93922188.79it/s]"
          }
        },
        "b790bceaddfc411b828c13abc8573f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b64780e6844aea9f8a2c2ff000c9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673d9404f3d04e5997a655152ef8b128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e72135498c584ab78c80a1651cf30788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "503478874974447da898867878b4cf76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9341f630dc14230badd6f10f33d5c41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9c5ab9839c4cf983f5b0835b365e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gohar-malik/anomaly-det/blob/main/cifar103.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d8f58ca16bd64a0386095fb59262f2b6",
            "e0f2063af0de4816bcf17dac04f83a64",
            "2f6c1b9a178d49b5850fb167cd003203",
            "328c3376343d4499be380e53e0625f5c",
            "b790bceaddfc411b828c13abc8573f3b",
            "30b64780e6844aea9f8a2c2ff000c9f3",
            "673d9404f3d04e5997a655152ef8b128",
            "e72135498c584ab78c80a1651cf30788",
            "503478874974447da898867878b4cf76",
            "a9341f630dc14230badd6f10f33d5c41",
            "fd9c5ab9839c4cf983f5b0835b365e96"
          ]
        },
        "id": "3jvvSXoKBnQx",
        "outputId": "17dc9757-294a-4447-c3d1-2bc9a7e96065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda:0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8f58ca16bd64a0386095fb59262f2b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch: 1\n",
            "Training:\tLoss: 1.6944\tLR: 0.050000\tTime: 50.22s\n",
            "Testing:\tLoss: 0.0112\tAcc: 0.4743\tTime:3.63s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/1_regular.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2\n",
            "Training:\tLoss: 1.2149\tLR: 0.050000\tTime: 43.08s\n",
            "Testing:\tLoss: 0.0082\tAcc: 0.6353\tTime:3.57s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/2_regular.pth\n",
            "Epoch: 3\n",
            "Training:\tLoss: 0.9637\tLR: 0.050000\tTime: 43.00s\n",
            "Testing:\tLoss: 0.0066\tAcc: 0.7019\tTime:3.11s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/3_regular.pth\n",
            "Epoch: 4\n",
            "Training:\tLoss: 0.8089\tLR: 0.050000\tTime: 43.02s\n",
            "Testing:\tLoss: 0.0065\tAcc: 0.7248\tTime:3.22s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/4_regular.pth\n",
            "Epoch: 5\n",
            "Training:\tLoss: 0.6817\tLR: 0.050000\tTime: 42.96s\n",
            "Testing:\tLoss: 0.0054\tAcc: 0.7757\tTime:3.75s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/5_regular.pth\n",
            "Epoch: 6\n",
            "Training:\tLoss: 0.5983\tLR: 0.050000\tTime: 43.11s\n",
            "Testing:\tLoss: 0.0046\tAcc: 0.8005\tTime:3.15s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/6_regular.pth\n",
            "Epoch: 7\n",
            "Training:\tLoss: 0.5348\tLR: 0.050000\tTime: 43.07s\n",
            "Testing:\tLoss: 0.0042\tAcc: 0.8189\tTime:3.12s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/7_regular.pth\n",
            "Epoch: 8\n",
            "Training:\tLoss: 0.4887\tLR: 0.050000\tTime: 43.09s\n",
            "Testing:\tLoss: 0.0040\tAcc: 0.8340\tTime:3.88s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/8_regular.pth\n",
            "Epoch: 9\n",
            "Training:\tLoss: 0.4512\tLR: 0.050000\tTime: 42.97s\n",
            "Testing:\tLoss: 0.0039\tAcc: 0.8368\tTime:3.11s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/9_regular.pth\n",
            "Epoch: 10\n",
            "Training:\tLoss: 0.4164\tLR: 0.050000\tTime: 43.20s\n",
            "Testing:\tLoss: 0.0036\tAcc: 0.8510\tTime:3.13s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/10_regular.pth\n",
            "Epoch: 11\n",
            "Training:\tLoss: 0.3865\tLR: 0.050000\tTime: 42.88s\n",
            "Testing:\tLoss: 0.0035\tAcc: 0.8588\tTime:3.90s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/11_regular.pth\n",
            "Epoch: 12\n",
            "Training:\tLoss: 0.3621\tLR: 0.050000\tTime: 43.01s\n",
            "Testing:\tLoss: 0.0036\tAcc: 0.8513\tTime:3.10s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/12_regular.pth\n",
            "Epoch: 13\n",
            "Training:\tLoss: 0.3386\tLR: 0.050000\tTime: 43.13s\n",
            "Testing:\tLoss: 0.0033\tAcc: 0.8598\tTime:3.13s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/13_regular.pth\n",
            "Epoch: 14\n",
            "Training:\tLoss: 0.3172\tLR: 0.050000\tTime: 43.00s\n",
            "Testing:\tLoss: 0.0030\tAcc: 0.8784\tTime:3.82s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/14_regular.pth\n",
            "Epoch: 15\n",
            "Training:\tLoss: 0.2966\tLR: 0.050000\tTime: 43.19s\n",
            "Testing:\tLoss: 0.0030\tAcc: 0.8720\tTime:3.08s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/15_regular.pth\n",
            "Epoch: 16\n",
            "Training:\tLoss: 0.2833\tLR: 0.050000\tTime: 43.05s\n",
            "Testing:\tLoss: 0.0031\tAcc: 0.8733\tTime:3.07s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/16_regular.pth\n",
            "Epoch: 17\n",
            "Training:\tLoss: 0.2646\tLR: 0.050000\tTime: 42.94s\n",
            "Testing:\tLoss: 0.0029\tAcc: 0.8825\tTime:4.02s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/17_regular.pth\n",
            "Epoch: 18\n",
            "Training:\tLoss: 0.2522\tLR: 0.050000\tTime: 42.88s\n",
            "Testing:\tLoss: 0.0029\tAcc: 0.8797\tTime:3.11s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/18_regular.pth\n",
            "Epoch: 19\n",
            "Training:\tLoss: 0.2350\tLR: 0.050000\tTime: 43.16s\n",
            "Testing:\tLoss: 0.0028\tAcc: 0.8873\tTime:3.10s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/19_regular.pth\n",
            "Epoch: 20\n",
            "Training:\tLoss: 0.2196\tLR: 0.050000\tTime: 42.97s\n",
            "Testing:\tLoss: 0.0029\tAcc: 0.8881\tTime:3.93s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/20_regular.pth\n",
            "Epoch: 21\n",
            "Training:\tLoss: 0.2109\tLR: 0.050000\tTime: 42.94s\n",
            "Testing:\tLoss: 0.0032\tAcc: 0.8812\tTime:3.10s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/21_regular.pth\n",
            "Epoch: 22\n",
            "Training:\tLoss: 0.1992\tLR: 0.050000\tTime: 43.13s\n",
            "Testing:\tLoss: 0.0032\tAcc: 0.8794\tTime:3.16s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/22_regular.pth\n",
            "Epoch: 23\n",
            "Training:\tLoss: 0.1908\tLR: 0.050000\tTime: 42.99s\n",
            "Testing:\tLoss: 0.0028\tAcc: 0.8903\tTime:3.92s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/23_regular.pth\n",
            "Epoch: 24\n",
            "Training:\tLoss: 0.1811\tLR: 0.050000\tTime: 42.98s\n",
            "Testing:\tLoss: 0.0027\tAcc: 0.8961\tTime:3.05s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/24_regular.pth\n",
            "Epoch: 25\n",
            "Training:\tLoss: 0.1718\tLR: 0.050000\tTime: 43.16s\n",
            "Testing:\tLoss: 0.0035\tAcc: 0.8777\tTime:3.08s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/25_regular.pth\n",
            "Epoch: 26\n",
            "Training:\tLoss: 0.1600\tLR: 0.050000\tTime: 43.03s\n",
            "Testing:\tLoss: 0.0028\tAcc: 0.8980\tTime:4.01s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/26_regular.pth\n",
            "Epoch: 27\n",
            "Training:\tLoss: 0.1556\tLR: 0.050000\tTime: 43.01s\n",
            "Testing:\tLoss: 0.0026\tAcc: 0.9006\tTime:3.12s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/27_regular.pth\n",
            "Epoch: 28\n",
            "Training:\tLoss: 0.1496\tLR: 0.050000\tTime: 43.05s\n",
            "Testing:\tLoss: 0.0029\tAcc: 0.8979\tTime:3.12s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/28_regular.pth\n",
            "Epoch: 29\n",
            "Training:\tLoss: 0.1407\tLR: 0.050000\tTime: 42.89s\n",
            "Testing:\tLoss: 0.0028\tAcc: 0.8964\tTime:3.90s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/29_regular.pth\n",
            "Epoch: 30\n",
            "Training:\tLoss: 0.1326\tLR: 0.050000\tTime: 42.92s\n",
            "Testing:\tLoss: 0.0029\tAcc: 0.8981\tTime:3.09s\n",
            "saving weights file to ./model_ResNet18_cifar10_b128_ep300_g0.1/30_regular.pth\n",
            "Using Device: cuda:0\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 625/625 [00:06<00:00, 97.38it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 1 err:  tensor(0.5257, device='cuda:0')\n",
            "Top 5 err:  tensor(0.0716, device='cuda:0')\n",
            "Parameter numbers: 11173962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(num_classes):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(epoch):\n",
        "\n",
        "    start = time.time()\n",
        "    net.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_index, (images, labels) in enumerate(cifar10_training_loader):\n",
        "        labels = labels.to(device)\n",
        "        images = images.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    finish = time.time()\n",
        "    print(f'Epoch: {epoch}')\n",
        "    print(f'Training:\\tLoss: {total_loss/len(cifar10_training_loader):0.4f}\\tLR: {optimizer.param_groups[0][\"lr\"]:0.6f}\\tTime: {finish-start:.2f}s')\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_training(epoch=0):\n",
        "\n",
        "    start = time.time()\n",
        "    net.eval()\n",
        "\n",
        "    test_loss = 0.0 # cost function error\n",
        "    correct = 0.0\n",
        "\n",
        "    for (images, labels) in cifar10_test_loader:\n",
        "        \n",
        "        labels = labels.to(device)\n",
        "        images = images.to(device)\n",
        "\n",
        "        outputs = net(images)\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum()\n",
        "\n",
        "    finish = time.time()\n",
        "\n",
        "    print(f'Testing:\\tLoss: {test_loss / len(cifar10_test_loader.dataset):.4f}\\tAcc: {correct.float() / len(cifar10_test_loader.dataset):.4f}\\tTime:{ finish - start:.2f}s')\n",
        "\n",
        "    return correct.float() / len(cifar10_test_loader.dataset)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-gpu', type=int, default=0, help='gpu id to use')\n",
        "parser.add_argument('-b', type=int, default=128, help='batch size for dataloader')\n",
        "parser.add_argument('-epochs', type=int, default=30, help='number of epochs to train')\n",
        "parser.add_argument('-lr', type=float, default=0.05, help='initial learning rate')\n",
        "parser.add_argument('-ckpt', default='./model_ResNet18_cifar10_b128_ep300_g0.1',help='directory of model for saving checkpoint')\n",
        "parser.add_argument('-ckptepoch', type=int, default=1 ,help='directory of model for saving checkpoint')\n",
        "parser.add_argument('--seed', type=int, default=42, help='random seed')\n",
        "parser.add_argument(\"-f\", required=False)\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "### device config\n",
        "use_cuda = (args.gpu is not None) and (torch.cuda.is_available())\n",
        "torch.manual_seed(args.seed)\n",
        "device = torch.device(f\"cuda:{args.gpu}\" if use_cuda else \"cpu\")\n",
        "print(f\"Using Device: {device}\")\n",
        "\n",
        "### network initialize\n",
        "net = ResNet18(num_classes=10).to(device)\n",
        "\n",
        "#### data loaders\n",
        "mean = (0.49139968, 0.48215827 ,0.44653124)\n",
        "std = (0.24703233,0.24348505,0.26158768)\n",
        "transform_train = transforms.Compose([\n",
        "    #transforms.ToPILImage(),\n",
        "    transforms.RandomCrop(32, padding=2),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "#cifar10_training = CIFAR10Train(path, transform=transform_train)\n",
        "cifar10_training = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "cifar10_training_loader = DataLoader(cifar10_training, shuffle=True, num_workers=2, batch_size=args.b)\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "#cifar10_test = CIFAR10Test(path, transform=transform_test)\n",
        "cifar10_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "cifar10_test_loader = DataLoader(cifar10_test, shuffle=True, num_workers=2, batch_size=args.b)\n",
        "\n",
        "### training config\n",
        "milestones = [150,225] #[60, 120, 160]\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.1e-4) #2e-4\n",
        "train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1) #0.2\n",
        "iter_per_epoch = len(cifar10_training_loader)\n",
        "\n",
        "### create checkpoint folder to save model\n",
        "checkpoint_path = args.ckpt\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    os.makedirs(checkpoint_path)\n",
        "checkpoint_path = os.path.join(checkpoint_path, '{epoch}_{type}.pth')\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(1, args.epochs+1):\n",
        "\n",
        "    train(epoch)\n",
        "    acc = eval_training(epoch)\n",
        "    train_scheduler.step(epoch)\n",
        "\n",
        "    #start to save best performance model after learning rate decay to 0.01\n",
        "    if epoch > milestones[0] and best_acc < acc:\n",
        "        weights_path = checkpoint_path.format(epoch=epoch, type='best')\n",
        "        print('saving weights file to {}'.format(weights_path))\n",
        "        torch.save(net.state_dict(), weights_path)\n",
        "        best_acc = acc\n",
        "        continue\n",
        "\n",
        "    if not epoch % args.ckptepoch:\n",
        "        weights_path = checkpoint_path.format(epoch=epoch, type='regular')\n",
        "        print('saving weights file to {}'.format(weights_path))\n",
        "        torch.save(net.state_dict(), weights_path)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-weights', type=str,default=\"/content/model_ResNet18_cifar10_b128_ep300_g0.1/1_regular.pth\", help='the weights file you want to test')\n",
        "parser.add_argument('-gpu', type=int, default=0, help='gpu id to use')\n",
        "parser.add_argument('-b', type=int, default=16, help='batch size for dataloader')\n",
        "parser.add_argument('-ckpt', type=str, default='checkpoints/', help='checkpoint directory path')\n",
        "\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "####### please add the path to the weights file here ######\n",
        "args.weights = \"/content/model_ResNet18_cifar10_b128_ep300_g0.1/1_regular.pth\"\n",
        "\n",
        "### device config\n",
        "use_cuda = (args.gpu is not None) and (torch.cuda.is_available())\n",
        "device = torch.device(f\"cuda:{args.gpu}\" if use_cuda else \"cpu\")\n",
        "print(f\"Using Device: {device}\")\n",
        "\n",
        "### network initialize\n",
        "net = ResNet18(num_classes=10).to(device)\n",
        "\n",
        "#### data loaders\n",
        "mean = (0.49139968, 0.48215827 ,0.44653124)\n",
        "std = (0.24703233,0.24348505,0.26158768)\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "cifar10_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "cifar10_test_loader = DataLoader(cifar10_test, shuffle=True, num_workers=4, batch_size=args.b)\n",
        "\n",
        "net.load_state_dict(torch.load(args.weights))\n",
        "# print(net)\n",
        "net.eval()\n",
        "\n",
        "correct_1 = 0.0\n",
        "correct_5 = 0.0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for n_iter, (image, label) in enumerate(tqdm(cifar10_test_loader)):\n",
        "        # print(\"iteration: {}\\ttotal {} iterations\".format(n_iter + 1, len(cifar100_test_loader)))\n",
        "\n",
        "        label = label.to(device)\n",
        "        image = image.to(device)\n",
        "\n",
        "\n",
        "        output = net(image)\n",
        "        _, pred = output.topk(5, 1, largest=True, sorted=True)\n",
        "\n",
        "        label = label.view(label.size(0), -1).expand_as(pred)\n",
        "        correct = pred.eq(label).float()\n",
        "\n",
        "        #compute top 5\n",
        "        correct_5 += correct[:, :5].sum()\n",
        "\n",
        "        #compute top1\n",
        "        correct_1 += correct[:, :1].sum()\n",
        "\n",
        "print()\n",
        "print(\"Top 1 err: \", 1 - correct_1 / len(cifar10_test_loader.dataset))\n",
        "print(\"Top 5 err: \", 1 - correct_5 / len(cifar10_test_loader.dataset))\n",
        "print(\"Parameter numbers: {}\".format(sum(p.numel() for p in net.parameters())))"
      ]
    }
  ]
}