{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gohar-malik/anomaly-det/blob/main/cifar100google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgvS7y4Q5QSl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(num_classes):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtMMD5ou6hzY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "94b705a2f6734c158c43cf973ce48223"
          ]
        },
        "id": "iu77Q4Qx6ifK",
        "outputId": "592326d0-74cf-4cb6-fe88-2278e7370c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Device: cpu\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94b705a2f6734c158c43cf973ce48223",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch: 1\n",
            "Training:\tLoss: 4.0246\tLR: 0.100000\tTime: 3207.78s\n",
            "Testing:\tLoss: 0.0288\tAcc: 0.1265\tTime:185.11s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2\n",
            "Training:\tLoss: 3.4642\tLR: 0.100000\tTime: 3143.24s\n",
            "Testing:\tLoss: 0.0260\tAcc: 0.2032\tTime:189.44s\n",
            "Epoch: 3\n",
            "Training:\tLoss: 3.0456\tLR: 0.100000\tTime: 3041.33s\n",
            "Testing:\tLoss: 0.0223\tAcc: 0.2785\tTime:182.72s\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "\n",
        "    start = time.time()\n",
        "    net.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_index, (images, labels) in enumerate(cifar100_training_loader):\n",
        "\n",
        "        labels = labels.to(device)\n",
        "        images = images.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    finish = time.time()\n",
        "    print(f'Epoch: {epoch}')\n",
        "    print(f'Training:\\tLoss: {total_loss/len(cifar100_training_loader):0.4f}\\tLR: {optimizer.param_groups[0][\"lr\"]:0.6f}\\tTime: {finish-start:.2f}s')\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_training(epoch=0):\n",
        "\n",
        "    start = time.time()\n",
        "    net.eval()\n",
        "\n",
        "    test_loss = 0.0 # cost function error\n",
        "    correct = 0.0\n",
        "\n",
        "    for (images, labels) in cifar100_test_loader:\n",
        "\n",
        "        labels = labels.to(device)\n",
        "        images = images.to(device)\n",
        "\n",
        "        outputs = net(images)\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum()\n",
        "\n",
        "    finish = time.time()\n",
        "\n",
        "    print(f'Testing:\\tLoss: {test_loss / len(cifar100_test_loader.dataset):.4f}\\tAcc: {correct.float() / len(cifar100_test_loader.dataset):.4f}\\tTime:{ finish - start:.2f}s')\n",
        "\n",
        "    return correct.float() / len(cifar100_test_loader.dataset)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-gpu', type=int, default=None, help='gpu id to use')\n",
        "    parser.add_argument('-b', type=int, default=128, help='batch size for dataloader')\n",
        "    parser.add_argument('-epochs', type=int, default=300, help='number of epochs to train')\n",
        "    parser.add_argument('-lr', type=float, default=0.1, help='initial learning rate')\n",
        "    parser.add_argument('-ckpt', default='./model_ResNet18_cifar100_b128_ep300_g0.1',help='directory of model for saving checkpoint')\n",
        "    parser.add_argument('-ckptepoch', type=int, default=25 ,help='directory of model for saving checkpoint')\n",
        "    parser.add_argument('--seed', type=int, default=42, help='random seed')\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    \n",
        "    ### device config\n",
        "    use_cuda = (args.gpu is not None) and (torch.cuda.is_available())\n",
        "    torch.manual_seed(args.seed)\n",
        "    device = torch.device(f\"cuda:{args.gpu}\" if use_cuda else \"cpu\")\n",
        "    print(f\"Using Device: {device}\")\n",
        "\n",
        "    ### network initialize\n",
        "    net = ResNet18(num_classes=100).to(device)\n",
        "\n",
        "    #### data loaders\n",
        "    mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "    std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "    transform_train = transforms.Compose([\n",
        "        #transforms.ToPILImage(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "    #cifar100_training = CIFAR100Train(path, transform=transform_train)\n",
        "    cifar100_training = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "    cifar100_training_loader = DataLoader(cifar100_training, shuffle=True, num_workers=4, batch_size=args.b)\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "    #cifar100_test = CIFAR100Test(path, transform=transform_test)\n",
        "    cifar100_test = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "    cifar100_test_loader = DataLoader(cifar100_test, shuffle=True, num_workers=4, batch_size=args.b)\n",
        "\n",
        "    ### training config\n",
        "    milestones = [150,225] #[60, 120, 160]\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4) #2e-4\n",
        "    train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1) #0.2\n",
        "    iter_per_epoch = len(cifar100_training_loader)\n",
        "\n",
        "    ### create checkpoint folder to save model\n",
        "    checkpoint_path = args.ckpt\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        os.makedirs(checkpoint_path)\n",
        "    checkpoint_path = os.path.join(checkpoint_path, '{epoch}_{type}.pth')\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "\n",
        "        train(epoch)\n",
        "        acc = eval_training(epoch)\n",
        "        train_scheduler.step(epoch)\n",
        "\n",
        "        #start to save best performance model after learning rate decay to 0.01\n",
        "        if epoch > milestones[0] and best_acc < acc:\n",
        "            weights_path = checkpoint_path.format(epoch=epoch, type='best')\n",
        "            print('saving weights file to {}'.format(weights_path))\n",
        "            torch.save(net.state_dict(), weights_path)\n",
        "            best_acc = acc\n",
        "            continue\n",
        "\n",
        "        if not epoch % args.ckptepoch:\n",
        "            weights_path = checkpoint_path.format(epoch=epoch, type='regular')\n",
        "            print('saving weights file to {}'.format(weights_path))\n",
        "            torch.save(net.state_dict(), weights_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rD1DGcm6bT9"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from resnet import ResNet18\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-weights', type=str, required=True, help='the weights file you want to test')\n",
        "    parser.add_argument('-gpu', type=int, default=None, help='gpu id to use')\n",
        "    parser.add_argument('-b', type=int, default=16, help='batch size for dataloader')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    ### device config\n",
        "    use_cuda = (args.gpu is not None) and (torch.cuda.is_available())\n",
        "    device = torch.device(f\"cuda:{args.gpu}\" if use_cuda else \"cpu\")\n",
        "    print(f\"Using Device: {device}\")\n",
        "\n",
        "    ### network initialize\n",
        "    net = ResNet18(num_classes=100).to(device)\n",
        "\n",
        "    #### data loaders\n",
        "    mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "    std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "    cifar100_test = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "    cifar100_test_loader = DataLoader(cifar100_test, shuffle=True, num_workers=4, batch_size=args.b)\n",
        "\n",
        "    net.load_state_dict(torch.load(args.weights))\n",
        "    # print(net)\n",
        "    net.eval()\n",
        "\n",
        "    correct_1 = 0.0\n",
        "    correct_5 = 0.0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for n_iter, (image, label) in enumerate(tqdm(cifar100_test_loader)):\n",
        "            # print(\"iteration: {}\\ttotal {} iterations\".format(n_iter + 1, len(cifar100_test_loader)))\n",
        "\n",
        "            label = label.to(device)\n",
        "            image = image.to(device)\n",
        "\n",
        "\n",
        "            output = net(image)\n",
        "            _, pred = output.topk(5, 1, largest=True, sorted=True)\n",
        "\n",
        "            label = label.view(label.size(0), -1).expand_as(pred)\n",
        "            correct = pred.eq(label).float()\n",
        "\n",
        "            #compute top 5\n",
        "            correct_5 += correct[:, :5].sum()\n",
        "\n",
        "            #compute top1\n",
        "            correct_1 += correct[:, :1].sum()\n",
        "\n",
        "    print()\n",
        "    print(\"Top 1 err: \", 1 - correct_1 / len(cifar100_test_loader.dataset))\n",
        "    print(\"Top 5 err: \", 1 - correct_5 / len(cifar100_test_loader.dataset))\n",
        "    print(\"Parameter numbers: {}\".format(sum(p.numel() for p in net.parameters())))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMNJMDaDia1UqPWTbHZUGu",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}